# AI Churn Prediction Model Documentation

This document outlines the key details of the AI Churn Prediction Model developed on TRAE.com IDE, aimed at providing insights into its functionality, performance, and potential for monetization.

## 1. Model Inputs:
- **Type of data:** The model takes structured data as input, primarily focusing on user behavior and subscription details. The specific features include:
    - `days_since_signup` (numerical)
    - `monthly_revenue` (numerical)
    - `number_of_logins_last30days` (numerical)
    - `active_features_used` (numerical)
    - `support_tickets_opened` (numerical)
    - `last_login_days_ago` (numerical)
    - `email_opens_last30days` (numerical)
    - `billing_issue_count` (numerical)
    - `subscription_plan` (categorical)
    - `last_payment_status` (categorical)
- **User Identification:** Each input record must include a `user_id` for identification purposes, though this is dropped before prediction.

## 2. Model Outputs:
- **Churn Probability:** The model returns a churn probability (a float between 0 and 1) for each user, indicating the likelihood of them churning.
- **Risk Level:** Based on the churn probability, a categorical risk level is assigned: "High" (probability > 0.7), "Medium" (0.4 <= probability <= 0.7), or "Low" (probability < 0.4).
- **Top Reasons for Churn:** Utilizing SHAP (SHapley Additive exPlanations) values, the model identifies and returns the top 2 features that positively contribute to a user's churn probability.

## 3. Accuracy & Validation:
- **Metrics:** The model's performance is evaluated using Accuracy and F1-Score.
- **Training and Evaluation:** The `train.py` script logs these metrics during the training process. Specific values for accuracy and F1-score are generated during training and would be found in the logs or `evaluation_report.txt`.
- **Data:** The model was trained and evaluated on `enhanced_saas_churn_data.csv`. While the exact nature (real-world vs. demo/sample) of this dataset is not explicitly stated in the code, it is a CSV file used for training.

## 4. Deployment Status:
- **Current Status:** The model is integrated into a Python application (`churnaizer/app.py`) and can be served via a `ChurnPredictorService` (defined in `churnaizer/src/predict.py`).
- **API/SDK:** There is a `churnaizer-api` directory with a `Dockerfile` and `app.py` (likely a Flask or FastAPI application), indicating that the model is intended to be deployed as an API. There's also a `churnaizer-sdk.js` which suggests a JavaScript SDK for interaction.
- **Usability:** Once deployed as an API, it can be used directly by other applications or services by sending user data and receiving churn predictions.

## 5. Differentiation:
- **Beyond Prediction:** While the core function is churn prediction, the model differentiates itself by providing **actionable insights** through SHAP-based "top reasons for churn." This moves beyond just predicting who will churn to explaining *why* they might churn.
- **Customization:** Unlike off-the-shelf tools, this model is built within a custom codebase, allowing for tailored feature engineering, model selection, and integration into specific business workflows.
- **Insights/Actions:** The `top_reasons` output can directly inform retention strategies, such as targeted email campaigns or personalized interventions based on the identified factors contributing to churn risk.

## 6. Technical Details:
- **Algorithm:** The model uses an **XGBoost Classifier** (`xgboost.XGBClassifier`).
- **Hyperparameter Tuning:** `GridSearchCV` is employed during training to find the optimal hyperparameters for the XGBoost model, ensuring robust performance.
- **Class Imbalance Handling:** `SMOTE (Synthetic Minority Over-sampling Technique)` is used to address class imbalance in the training data, preventing the model from being biased towards the majority class (non-churners).
- **Data Preprocessing:** Data undergoes preprocessing, including handling missing values (imputation with mode for categorical, mean for numerical) and one-hot encoding for categorical features using `OneHotEncoder`.
- **Data Size:** The training data is loaded from `data/enhanced_saas_churn_data.csv`. The exact number of records is not hardcoded but is processed dynamically. The quality of data is managed through missing value imputation and feature engineering.

## 7. Target Audience:
- **Primary Audience:** The model is well-suited for **SaaS businesses, subscription-based applications, and potentially B2B SaaS companies** that collect detailed user behavior and subscription data.
- **Data Integration:** The model expects structured data. While it handles some preprocessing (missing values, one-hot encoding), users would need to provide their data in a format consistent with the expected features. Direct upload would require data to be pre-aligned with the model's input schema, or a custom data ingestion layer would be needed for more flexible data integration.