# -*- coding: utf-8 -*-
"""Churnaizer Colab Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

# Churnaizer: Churn Prediction and Recovery Tracking System

# This notebook will guide you through setting up and running the Churnaizer model,
# generating comprehensive reports, and sending email notifications.

# --- SECTION 1: Setup and Dependencies ---
# Run this cell to install all necessary libraries. If running in Google Colab, some might be pre-installed.
# Install required packages
!pip install pandas scikit-learn joblib matplotlib reportlab openrouter Flask flask-cors APScheduler uvicorn

import joblib
import os
import requests
import matplotlib.pyplot as plt
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.units import inch
from reportlab.lib import colors
import pandas as pd
import logging
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication

# Configure logging for the report generator
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- SECTION 2: Load Model and Preprocessor ---
# Upload your 'churnaizer_saas_model.pkl' and 'one_hot_encoder.pkl' files to your Colab environment.
# You can do this by dragging and dropping them into the Colab file browser (left sidebar -> Files icon).

model_path = 'churnaizer_saas_model.pkl'
preprocessor_path = 'one_hot_encoder.pkl'

try:
    model = joblib.load(model_path)
    preprocessor = joblib.load(preprocessor_path)
    print(f"Model and preprocessor loaded successfully from {model_path} and {preprocessor_path}")
except FileNotFoundError:
    print(f"Error: Make sure '{model_path}' and '{preprocessor_path}' are uploaded to your Colab environment.")
except Exception as e:
    print(f"An error occurred while loading the model or preprocessor: {e}")

# --- SECTION 3: AI Email Generation (OpenRouter API) ---
# Get your OpenRouter API key from https://openrouter.ai/keys
# It is highly recommended to store your API key securely using Colab secrets.
# Go to the left sidebar -> Key icon (Secrets) -> Add a new secret with name 'OPENROUTER_API_KEY' and your API key as value.
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY") or "YOUR_OPENROUTER_API_KEY" # Replace if not using Colab secrets

def generate_email_with_openrouter(prompt, model="google/gemini-pro", customer_name="Customer", churn_reason="low engagement"):
    if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == "YOUR_OPENROUTER_API_KEY":
        return "Error: OpenRouter API key not set or is default. Please set your API key."

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Using a free tier model, you might need to adjust the model name based on OpenRouter's current offerings
    # For example, 'google/gemini-pro' or 'meta-llama/llama-3-8b-instruct:free'
    # Check OpenRouter documentation for available free models and their exact names.
    
    data = {
        "model": model,
        "prompt": f"You are an AI assistant that writes personalized re-engagement emails. Write a concise and empathetic email to {customer_name} who is at risk of churning due to {churn_reason}. The email should encourage them to continue using the service and offer a solution or incentive. \n\nEmail content: {prompt}",
        "max_tokens": 300
    }

    try:
        response = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, json=data)
        response.raise_for_status()  # Raise an exception for HTTP errors
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        return f"Error calling OpenRouter API: {e}"

# --- SECTION 4: Report Generation Function ---
# This function generates a PDF report based on churn analysis.

def generate_report_pdf(processed_df: pd.DataFrame, stats_summary: dict, output_filepath: str):
    doc = SimpleDocTemplate(output_filepath, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []

    # Ensure the output directory for charts exists
    chart_dir = os.path.dirname(output_filepath)
    if chart_dir and not os.path.exists(chart_dir):
        os.makedirs(chart_dir, exist_ok=True)

    # Title
    story.append(Paragraph("Churnaizer Churn Audit Report", styles['h1']))
    story.append(Spacer(1, 0.2 * inch))

    # Executive Summary
    story.append(Paragraph("Executive Summary", styles['h2']))
    summary_text = f"""
    This report provides an in-depth analysis of customer churn risk based on the provided data.
    Out of {stats_summary.get('total_customers', 0)} customers,
    {stats_summary.get('churn_distribution', {}).get('high_risk_percent', 0):.2f}% are identified as high risk,
    {stats_summary.get('churn_distribution', {}).get('medium_risk_percent', 0):.2f}% as medium risk, and
    {stats_summary.get('churn_distribution', {}).get('low_risk_percent', 0):.2f}% as low risk.
    The average churn score across all customers is {stats_summary.get('churn_distribution', {}).get('average_churn_score', 0):.2f}.
    """
    story.append(Paragraph(summary_text, styles['Normal']))
    story.append(Spacer(1, 0.2 * inch))

    # Churn Risk Distribution Chart
    story.append(Paragraph("Churn Risk Distribution", styles['h2']))
    if 'risk_level' in processed_df.columns:
        risk_counts = processed_df['risk_level'].value_counts()
        if not risk_counts.empty:
            plt.figure(figsize=(6, 4))
            plt.pie(risk_counts, labels=risk_counts.index, autopct='%1.1f%%', startangle=90)
            plt.title('Churn Risk Distribution')
            plt.axis('equal')
            chart_path = os.path.join(chart_dir, "churn_risk_distribution.png")
            os.makedirs(os.path.dirname(chart_path), exist_ok=True)
            plt.savefig(chart_path)
            plt.close()
            story.append(Image(chart_path, width=400, height=300))
            story.append(Spacer(1, 0.1 * inch))
        else:
            story.append(Paragraph("No churn risk data available for charting.", styles['Normal']))
    else:
        story.append(Paragraph("Churn risk level column not found in processed data.", styles['Normal']))
    story.append(Spacer(1, 0.2 * inch))

    # Risky Users Table (Top 10)
    story.append(Paragraph("High-Risk Customers (Top 10)", styles['h2']))
    if 'risk_level' in processed_df.columns and 'user_id_masked' in processed_df.columns and 'churn_score' in processed_df.columns:
        high_risk_users = processed_df[processed_df['risk_level'] == 'High'].sort_values(by='churn_score', ascending=False).head(10)
        if not high_risk_users.empty:
            data = [['Masked User ID', 'Churn Score', 'Risk Level', 'Reason']]
            for index, row in high_risk_users.iterrows():
                data.append([
                    row.get('user_id_masked', 'N/A'),
                    f"{row.get('churn_score', 0):.2f}",
                    row.get('risk_level', 'N/A'),
                    row.get('reason', 'N/A')
                ])
            
            table = Table(data)
            table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(table)
        else:
            story.append(Paragraph("No high-risk customers identified.", styles['Normal']))
    else:
        story.append(Paragraph("Required columns for risky users table not found.", styles['Normal']))
    story.append(Spacer(1, 0.2 * inch))

    # Build PDF
    try:
        doc.build(story)
        logging.info(f"PDF report successfully generated at {output_filepath}")
    except Exception as e:
        logging.error(f"Error building PDF: {e}")
        raise

# --- SECTION 5: Email Notification Function ---
# This function sends email notifications with optional attachments.
# Email configuration (replace with your details or Colab secrets)
SENDER_EMAIL = "your_email@example.com"
SENDER_PASSWORD = "your_email_password" # Use Colab secrets for this!
SMTP_SERVER = "smtp.gmail.com"  # Example for Gmail
SMTP_PORT = 587

def send_email_notification(recipient_email, subject, body, attachment_path=None):
    msg = MIMEMultipart()
    msg['From'] = SENDER_EMAIL
    msg['To'] = recipient_email
    msg['Subject'] = subject

    msg.attach(MIMEText(body, 'plain'))

    if attachment_path:
        try:
            with open(attachment_path, "rb") as f:
                attach = MIMEApplication(f.read(), _subtype="pdf")
            attach.add_header('Content-Disposition', 'attachment', filename=os.path.basename(attachment_path))
            msg.attach(attach)
        except FileNotFoundError:
            print(f"Warning: Attachment file not found at {attachment_path}")
        except Exception as e:
            print(f"Error attaching file {attachment_path}: {e}")

    try:
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:
            server.starttls()  # Secure the connection
            server.login(SENDER_EMAIL, SENDER_PASSWORD)
            server.send_message(msg)
        print(f"Email sent successfully to {recipient_email}")
    except Exception as e:
        print(f"Error sending email to {recipient_email}: {e}")

# --- SECTION 6: Main Churnaizer Workflow ---
# This function orchestrates the entire churn analysis and notification process.

def run_churnaizer_workflow(input_csv_path, output_report_path, admin_recipient_emails):
    print("\n--- Starting Churnaizer Workflow ---")

    # 6.1. Data Loading and Preprocessing (Placeholder)
    print("Loading and preprocessing data...")
    # In a real scenario, you would load your CSV here and preprocess it using the preprocessor.
    # Example: raw_data = pd.read_csv(input_csv_path)
    #          processed_data = preprocessor.transform(raw_data[feature_columns])
    # For demonstration, let's create a dummy DataFrame with necessary columns.
    dummy_data = {
        'user_id': [f'user_{i}' for i in range(1, 11)],
        'user_id_masked': [f'masked_{i}' for i in range(1, 11)],
        'feature_1': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
        'feature_2': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
        'email': [f'user{i}@example.com' for i in range(1, 11)],
        'churn_score': [0.95, 0.88, 0.75, 0.60, 0.55, 0.40, 0.30, 0.20, 0.10, 0.05],
        'risk_level': ['High', 'High', 'High', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],
        'reason': ['High Price', 'Poor Support', 'Missing Feature', 'Competitor Offer', 'Lack of Use', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']
    }
    processed_df = pd.DataFrame(dummy_data)
    print("Data loaded and preprocessed (using dummy data for demonstration).")

    # 6.2. Churn Prediction (Placeholder)
    print("Making churn predictions...")
    # In a real scenario, you would use the loaded model to predict churn scores.
    # Example: predictions = model.predict_proba(processed_data)[:, 1]
    #          processed_df['churn_score'] = predictions
    #          processed_df['risk_level'] = pd.cut(processed_df['churn_score'], bins=[0, 0.3, 0.7, 1.0], labels=['Low', 'Medium', 'High'])
    print("Churn predictions made (using dummy data for demonstration).")

    # 6.3. Generate Report
    print(f"Generating churn report to {output_report_path}...")
    stats_summary = {
        "total_customers": len(processed_df),
        "churn_distribution": {
            "high_risk_percent": (processed_df['risk_level'] == 'High').sum() / len(processed_df) * 100,
            "medium_risk_percent": (processed_df['risk_level'] == 'Medium').sum() / len(processed_df) * 100,
            "low_risk_percent": (processed_df['risk_level'] == 'Low').sum() / len(processed_df) * 100,
            "average_churn_score": processed_df['churn_score'].mean()
        }
    }
    generate_report_pdf(processed_df, stats_summary, output_report_path)
    print("Churn report generated.")

    # 6.4. AI Email Generation and Notification for High-Risk Customers
    print("Generating and sending personalized emails to high-risk customers...")
    high_risk_customers = processed_df[processed_df['risk_level'] == 'High']

    for index, customer in high_risk_customers.iterrows():
        customer_name = customer['user_id_masked'] # Using masked ID as name for privacy
        customer_email = customer['email']
        churn_reason = customer['reason']

        email_prompt = f"Write a re-engagement email for {customer_name} who is at risk of churning due to {churn_reason}. Offer a 20% discount on their next month's subscription."
        generated_email_body = generate_email_with_openrouter(email_prompt, customer_name=customer_name, churn_reason=churn_reason)

        if "Error" not in generated_email_body:
            subject = f"Don't Leave Us, {customer_name}! Here's a Special Offer!"
            full_email_body = f"Dear {customer_name},\n\n{generated_email_body}\n\nBest regards,\nChurnaizer Team"
            send_email_notification(customer_email, subject, full_email_body, output_report_path)
        else:
            print(f"Skipping email for {customer_name} due to OpenRouter API error: {generated_email_body}")

    # 6.5. Notify Admin/Stakeholders
    print("Notifying admin/stakeholders...")
    admin_subject = "Churnaizer Workflow Completed - New Churn Report Available"
    admin_body = f"Dear Admin,\n\nThe Churnaizer workflow has completed. A new churn analysis report is attached.\n\nBest regards,\nChurnaizer System"
    for admin_email in admin_recipient_emails:
        send_email_notification(admin_email, admin_subject, admin_body, output_report_path)

    print("\n--- Churnaizer Workflow Completed ---")

# --- SECTION 7: Example Usage ---
# To run the full workflow, uncomment the lines below and replace with your actual values.
input_csv_file = "your_customer_data.csv"  # Make sure this file is uploaded to Colab
output_pdf_file = "churn_analysis_report.pdf"
admin_emails = ["shaikhsadique730@gmail.com", "another_admin@example.com"]

run_churnaizer_workflow(input_csv_file, output_pdf_file, admin_emails)

# Remember to set your SENDER_EMAIL, SENDER_PASSWORD, and OPENROUTER_API_KEY in the respective sections or as Colab secrets.